\section{Population games based on habitat choice}
\label{sec:general_setting}
We build the general setting piece-by-piece, from the environment to the foraging strategies. First we define the environment, then we introduce the mean-field setting, as it is necessary to handle the strategy of an entire population. With this in place, we can give an exact definition of a population game in our sense. Once we have laid the building blocks for our setting, we show that mean-field games generalize the ideal free distribution.


We envision a setting with $M$ different types of unstructured populations of animals co-existing in an environment, each with biomass $N_i$. We only model behavior as patch choice, excluding e.g. mating behavior. The distribution of population $i$ in the environment is described by $\overbar{\sigma}_i$.  More rigorously, we assume that the environment is a probability space $(X,\mu)$. Modeling the environment as a probability space allows us to model habitats which are continuous, discrete and mixtures thereof in the same context. As an example, bats forage over a continuous area while the caves where they rest are discrete and disconnected \citep{collet2019algorithmic}. We model that the populations $N_i$, $i\in \{1,\dots,M\}$  are large compared to a single individual. This allows us to consider the population as continuous, consisting of infinitely many individuals. We assume that the population dynamics depend both on the distributions and the population sizes:
\begin{equation}
  \label{eq:vk_dyn}
  \dot{N}_i = N_i f_i((N_j,\overbar{\sigma}_j)_{j=1}^M)
\end{equation}
That is, we consider population dynamics of the Lotka-Volterra type.


% so $N_i$ are continuous%, and so is the model. )% This allows us to model the population as continuous.ny
We suppose that the migration dynamics happen on a faster time-scale than the population dynamics, as is seen with e.g. vertical migrations in marine ecosystems \citep{iwasa1982vertical}. This slow-fast dynamic allows us to model the migrations as instantaneous, with each individual picking the optimal foraging ground at every instant \citep{kvrivan2013behavioral, cressman2006migration}.


We assume that every animal has an area where it forages at every instant. For an animal of type $i$ this is described by a probability distribution $\sigma_i$ over the environment $X$. We require that the distribution $\sigma_i$ is absolutely continuous with respect to the measure $\mu$. In an abuse of notation, we will denote this density by $\sigma$. We denote the space of probability densities over $X$ with respect to $\mu$ by $P_{\mu}$. We suppress $X$ for notational brevity. By requiring absolute continuity with respect to the base measure we remove degenerate Nash equilibria e.g. Dirac-type distributions in a continuous setting, avoiding for example all gazelles stacked exactly at a single point in space. By working in this generality, we generalize both the continuous and discrete approach to habitat selection \citep{fretwell1969territorial, broom2013game, verticalmigration}.


\subsection{Foraging strategies and mean-field}
An animal actively chooses where it forages, and we model that an animal is always foraging. Hence the density $\sigma_i$ describing where it forages is a strategic choice for an animal. In order to inform this choice, we need to establish the playing field. An animal of type $i$ faces the foraging choices of all other inhabitants. Modeling the influence of the foraging choices necessitates the introduction of the mean-field-strategy, $\overbar{\sigma}_j$ for type $j$. The mean-field strategy $\overbar{\sigma}_j$ is the average strategy of all individuals of type $j$. As a consequence, we can describe the foraging presence from type $j$ at a point $x\in X$ by $N_j \overbar{\sigma}_j(x)$.


The choice of optimal foraging strategy $\sigma_i^*$ for an animal of type $i$ is a trade-off based on the presence of competitors, predators and prey. The mean density of competitors, predators and prey at a point $x$ is described by $N_j \overbar{\sigma}_j(x)$. We capture this trade-off in a payoff function $U_i(\sigma_i, (N_j \overbar{\sigma}_j)_{j=1}^M)$. The goal of a single animal of type $i$ is finding the optimal strategy $\sigma_i^*$ such that
\begin{equation}
  \label{eq:ind_opt}
  \sigma^*_i = \argmax_{\sigma_i \in P_{\mu}} U_i(\sigma_i, (N_j, \overbar{\sigma}_j)_{j=1}^M)
\end{equation}
The fundamental assumption in a mean-field game is that the populations consist of infinitely many individuals acting instantaneously and independently so the choice of a single individual does not change the mean-field strategy \citep{aumann1964markets}. At the Nash equilibrium of a mean-field game every individual of type $i$ follows the same strategy $\sigma_i^*$, \citep{lasry2007mean, aumann1964markets}. Heuristically, this is due to interchangeability as if any individual of type $i$ gains by deviating from $\sigma_i^*$, any one of them would also gain from making the same deviation, hence doing so. Therefore, if they all follow the optimal strategy, they follow the same strategy. This allows us to go from the individual-level optimization to the Nash equilibrium in \Cref{eq:ind_opt}. %Considering $\sigma^*_{j}$ as a function of $\overbar{\sigma}_j$ the Nash equilibrium $\overbar{\sigma}_j^N$ for the mean-field game is the solution to the equation:
%\begin{equation}
%  \sigma^*_{j}(\overbar{\sigma}^N_j) = \overbar{\sigma}^N_j
%\end{equation}
Using $^N$ to denote the Nash equilibrium, the mean-field equilibrium $\overbar{\sigma}_i^N$ is the solution to the equation:
\begin{equation}
  \label{eq:mfg_ne}
  \overbar{\sigma}_i^N = \pa{\argmax_{\sigma_i \in P_{\mu}} U_i(\sigma_i, (N_j \overbar{\sigma}_j)_{j=1, j\neq i}^M, N_i \overbar{\sigma}_i^N) }
\end{equation}
Hence the Nash equilibrium of a game with $M$ interacting populations is the solution to the system of equations:
\begin{equation}
  \label{eq:tot_nash_eq}
  \begin{split}
    \overbar{\sigma}_1^N = \pa{\argmax_{\sigma_1 \in P_{\mu}} U_1(\sigma_1, (N_j \overbar{\sigma}^N_j)_{j=1}^M) } \\
    \vdots \\
    \overbar{\sigma}_M^N = \pa{\argmax_{\sigma_M \in P_{\mu}} U_M(\sigma_M, (N_j \overbar{\sigma}^N_j)_{j=1}^M) }
    \end{split}
\end{equation}
This system of equations looks intractable, but in the next section we will see that in many cases it can actually be solved using the toolbox of variational inequalities. Introducing \Cref{eq:tot_nash_eq} allows us to define a population game exactly.
%2) Polymorphic-Monomorphic equivalence
\begin{definition}\label{def:pop_game}
  A population game consists of $M$ unstructured populations with each population having a biomass of size $N_i$ with dynamics given by \Cref{eq:vk_dyn}. Each individual of type $i$ has a payoff function $U_i(\sigma_i,  (N_j \overbar{\sigma}_j)_{j=1}^M))$. Migrations are instantanenous, and at every instant the populations are distributed according to the Nash equilibrium \Cref{eq:tot_nash_eq}, $\overbar{\sigma}_i^N$.
\end{definition}
%Advantages of general approach:
%1) Easily generalizes IFD
\subsection{The ideal free distribution and mean-field games}
Assuming monomorphic populations is the typical approach to population games with instantaneous migrations  \citep{kvrivan2013behavioral, vincent2005evolutionary}, but it is well-known that this does not generalize the ideal-free distribution and dramatically increases the pr. capita gain \citep{kvrivan2008ideal}. We show that mean-field games generalize the classical ideal free distribution, in the vein of \citep{cressman2010ideal}, specialized here to a linear density-dependence for clarity \cite{cressman2004ideal}. The proof, however, goes through for general functions of density dependence \citep{fretwell1969territorial}.


%e show that the difference between assuming a game is monomorphic and having monomorphism emerge from a mean-field approach is substantial.  The difference has been studied qualitively \citep{kvrivan2008ideal,collet2019algorithmic}. %AndAbrams
\begin{comment}
\begin{definition}
  In a monomorphic game the populations are assumed monomorphic. That is, for any individual of type $j$, we have $\sigma_j = \overbar{\sigma}_j$. Hence, an individual of type $i$ seeks to find $\sigma_i^*$ as:
  \begin{equation}
    \label{eq:ind_opt}
    \sigma^*_i = \argmax_{\sigma_i \in P_{\mu}} U_i(\sigma_i, (N_j, (\sigma}_j)_{j=1}^M)
  \end{equation}
\end{definition}
With the precise definition of a monomorphic game nailed down, we can show the claimed result:
\end{comment}
%In order to proceed, we recall the  (KKT) conditions:
%\begin{theorem}
%KKT CONDITIONS HERE
%\end{theorem}
Consider a population of size $N$ a discrete space $X$ with $L$ points. To emphasize the discrete nature, the strategy of an individual is denoted $p$ rather than $\sigma$ and the mean-field strategy then becomes $\overbar{p}$.

The payoff function $U(p,N\overbar{p})$ for an individual playing strategy $p$ is an affine function. The function $U$ is specified by an $m\times m$ matrix $A$ encapsulating the density dependence and a vector $b$ giving the spot-wise payoff. Then $U(p,N\overbar{p}) = N\ip{p}{A \overbar{p}} + \ip{p}{b}$. Denote the Nash equilibria for the mean-field game by $p^N$.
\begin{proposition}
  \label{prop:doubleup}
  The Nash equilibrium for the mean-field game $p^{N}$ is the ideal free distribution.
\end{proposition}
\begin{proof}
Consider the payoff in the mean-field situation $U(p,\overbar{p})$.
\begin{align}
  U(p, \overbar{p}) = N \ip{p}{A\overbar{p}}
\end{align}
Using the KKT conditions and defining $e$ as the vector with $L$ ones, we can write up the requirements for an extremum $p^{N}$. The Lagrange multiplier $\lambda$ comes from the constraint that $p$ is a probability vector, and the complementarity slackness $\nu$ comes from the non-negativity of $p$.
\begin{equation}
  \begin{split}
    N \cdot A\overbar{p} + b + \mu = \lambda e \\
    \ip{p^{N}}{\nu} = 0 \\
    \nu \geq 0,~p^{N} \geq 0 \\
    \sum_{j=1}^L p^{N,j} = 1
  \end{split}
\end{equation}
As we are in the mean-field case, at the Nash equilibrium $p^N = \overbar{p}$ \Cref{eq:mfg_ne}.
so we can insert $p^N=\overbar{p}$ in the KKT conditions, to get:
\begin{equation}
  \begin{split}
    N \cdot Ap^{N} + b + \nu =  \lambda_1 e \\
    \ip{p^N}{\nu} = 0 \\
    \nu \geq 0,~p^{N} \geq 0 \\
    \sum_{j=1}^L p^{N,j} = 1
  \end{split}
\end{equation}
The first equation ensures that $N\cdot Ap + b + \mu$ is constant. At the same time, $p=0$ whenever $\mu > 0$ due to the second equation. Hence $N\cdot Ap^{N} + b$ is constant, and equals $\lambda$. For any $j$ where $(N\cdot Ap)_j$ would be less than $\lambda$, the value of $p_j$ is zero.
These are exactly the criteria for the ideal free distribution \citep{fretwell1969territorial}, illustrating the ideal free distribution as a special case of a mean-field game.
\qed
\end{proof}
%That is, assuming a monomorphic population doubles the payoff at the Nash equilibrium.
In \Cref{prop:doubleup} the ideal free distribution emerges as the mean-field equilibrium. The emergence of the ideal-free distribution is a compelling argument for the mean-field model for modeling population games.
\begin{comment}
\begin{example}
  If we go back to the model in \Cref{prop:doubleup} and denote the identity matrix on $\R^n$ by $I_n$. Assume that $A=-I_2$ $b=(2,1)$ then assuming a monomorphic population leads to a dramatic increase in fitness and a different distribution compared to the mean-field approach. Assuming a monomorphic population in \Cref{prop:doubleup}, the payoff function is affine-quadratic $U(p,N p) = N \ip{p}{Ap} + \ip{b}{p}$.

\end{example}
In comparison, \Cref{prop:doubleup} shows that assuming a monomorphic population doubles the payoff compared to the ideal free distribution. This shows that the selflessness of an individual from assuming a monomorphic population is not insignificant, even in simple models.
\end{comment}
